{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/MADscientist314/TensorFlow/blob/master/MNIST_tutorial.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DwEL5iaF6mJI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fge1201j6sJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "410458aa-8735-4107-b57b-964cb2f84d4f"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jwZvjqL36z7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5493267-72b0-4bd7-f8fb-0e741433c995"
      },
      "cell_type": "code",
      "source": [
        "mnist.train.images.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "v_60OEqk7pNz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2929
        },
        "outputId": "8792edda-cf4e-44b3-8bd1-d4eb832dabca"
      },
      "cell_type": "code",
      "source": [
        "sample_img = mnist.train.images[5].reshape(28,28)\n",
        "sample_img"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.23137257, 0.6392157 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
              "        0.7607844 , 0.43921572, 0.07058824, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.01568628, 0.5176471 ,\n",
              "        0.93725497, 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
              "        0.9960785 , 0.9921569 , 0.627451  , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.5372549 , 0.9921569 ,\n",
              "        0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 , 0.75294125,\n",
              "        0.9960785 , 0.9921569 , 0.8980393 , 0.0509804 , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01568628, 0.5372549 , 0.9843138 , 0.9921569 ,\n",
              "        0.9568628 , 0.50980395, 0.19215688, 0.07450981, 0.01960784,\n",
              "        0.6392157 , 0.9921569 , 0.8235295 , 0.03529412, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.37254903, 0.9921569 , 0.9921569 , 0.8431373 ,\n",
              "        0.1764706 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.6117647 , 0.9921569 , 0.68235296, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.8431373 , 0.9960785 , 0.8117648 , 0.09019608,\n",
              "        0.        , 0.        , 0.        , 0.03921569, 0.3803922 ,\n",
              "        0.85098046, 0.9176471 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.83921576, 0.9921569 , 0.2784314 , 0.        ,\n",
              "        0.        , 0.00784314, 0.19607845, 0.8352942 , 0.9921569 ,\n",
              "        0.9960785 , 0.7058824 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.83921576, 0.9921569 , 0.19215688, 0.        ,\n",
              "        0.        , 0.19607845, 0.9921569 , 0.9921569 , 0.9921569 ,\n",
              "        0.7176471 , 0.04705883, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.7803922 , 0.9921569 , 0.95294124, 0.7686275 ,\n",
              "        0.62352943, 0.95294124, 0.9921569 , 0.9686275 , 0.5411765 ,\n",
              "        0.03137255, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.16470589, 0.9921569 , 0.9921569 , 0.9921569 ,\n",
              "        0.9960785 , 0.9921569 , 0.9921569 , 0.39607847, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.23137257, 0.58431375, 0.9960785 , 0.9960785 , 0.9960785 ,\n",
              "        1.        , 0.9960785 , 0.6862745 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.13333334, 0.75294125,\n",
              "        0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 , 0.7843138 ,\n",
              "        0.53333336, 0.89019614, 0.9450981 , 0.27058825, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33333334, 0.9686275 , 0.9921569 ,\n",
              "        0.9960785 , 0.9921569 , 0.77647066, 0.48235297, 0.07058824,\n",
              "        0.        , 0.19607845, 0.9921569 , 0.8352942 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.2784314 , 0.9686275 , 0.9921569 , 0.9294118 ,\n",
              "        0.75294125, 0.2784314 , 0.02352941, 0.        , 0.        ,\n",
              "        0.        , 0.00784314, 0.5019608 , 0.9803922 , 0.21176472,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.46274513, 0.9921569 , 0.8705883 , 0.14117648,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.03137255, 0.7176471 , 0.9921569 , 0.227451  ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.46274513, 0.9960785 , 0.54509807, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.05490196, 0.7294118 , 0.9960785 , 0.9960785 , 0.227451  ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.2784314 , 0.9686275 , 0.9686275 , 0.54509807,\n",
              "        0.0627451 , 0.        , 0.        , 0.07450981, 0.227451  ,\n",
              "        0.87843144, 0.9921569 , 0.9921569 , 0.8313726 , 0.03529412,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.42352945, 0.9921569 , 0.9921569 ,\n",
              "        0.92549026, 0.6862745 , 0.6862745 , 0.9686275 , 0.9921569 ,\n",
              "        0.9960785 , 0.9921569 , 0.77647066, 0.16862746, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.2627451 , 0.8352942 , 0.8980393 ,\n",
              "        0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
              "        0.83921576, 0.48627454, 0.02352941, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.09019608,\n",
              "        0.60784316, 0.60784316, 0.8745099 , 0.7843138 , 0.46274513,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Z1igAm7k71wd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "2fefe46c-d6ba-475e-aacb-0b2f20c92382"
      },
      "cell_type": "code",
      "source": [
        "#plot the image\n",
        "plt.imshow(sample_img).set_cmap('Greys')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngIIuEoCCLhKAgi4SgIIuEsD/A+j9L3wFjreIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7efe664d6668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "yDCaTL_z8GvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bef6e9c8-6c54-4274-fe61-591a3d6b6309"
      },
      "cell_type": "code",
      "source": [
        "# check MNIST labels shape\n",
        "mnist.train.labels.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "ZYqZVTPT8Z3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee9a6f41-3274-41b1-ad7b-4c00b18255b6"
      },
      "cell_type": "code",
      "source": [
        "sample_label = mnist.train.labels[5]\n",
        "sample_label"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "KjqxDNVZ8mZr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define a neural network (softmax logistic regression)\n",
        "import tensorflow as tf\n",
        "x = tf.placeholder(tf.float32, [None, 784]) #define x as the input\n",
        "W = tf.Variable(tf.zeros([784, 10])) # define w as the hidden state 1\n",
        "\n",
        "b = tf.Variable(tf.zeros([10])) #define b as the hidden state 2\n",
        "y = tf.nn.softmax(tf.matmul(x, W) + b) #  define the equation using softmax logistic regression "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vo7Eb_NK8rUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "acc62384-8b32-4579-a375-43dc5258aa20"
      },
      "cell_type": "code",
      "source": [
        "# define the train step to minimize the cross entropy with SGD\n",
        "y_ = tf.placeholder(tf.float32, [None, 10]) #define y_ as a placeholder for your input from the findings of the first round of selection\n",
        "cross_entropy = -tf.reduce_sum(y_*tf.log(y)) # minimize loss somehow??\n",
        "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy) #Also a magic box for optimization\n",
        "train_step # conduct the optimization step"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Operation 'GradientDescent_1' type=NoOp>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "7564WIuy8vAr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize variables and session \n",
        "init = tf.global_variables_initializer() # initialize the global variable\n",
        "sess = tf.Session() # begin a session\n",
        "sess.run(init) #run the session\n",
        "\n",
        "# train the model mini batch with 100 elements, for 1K times\n",
        "for i in range(1000): #relearn this thing by rerunning it 1000 arbitrary number times\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(100) #define batch_x and batch y  in increments of 100?\n",
        "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys}) # run the session with the 100 batches pooled together"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dA6cRrCE-NQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "5d0697b8-dbae-4cf3-d8ce-d7fde97240d5"
      },
      "cell_type": "code",
      "source": [
        "# evaluate the accuracy of the model\n",
        "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1)) # run the statistics to see how close the computer got to the real thing\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
        "tensorboard --logdir=path/to/log-directory"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-e2f45b746f39>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    tensorboard --logdir=path/to/log-directory\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "pWYrI-A3-VwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "209f2d9d-b24c-4d0b-faf3-12d1278d3dc1"
      },
      "cell_type": "code",
      "source": [
        " # Train the model, and also write summaries.\n",
        "  # Every 10th step, measure test-set accuracy, and write test summaries\n",
        "  # All other steps, run train_step on training data, & add training summaries\n",
        "def feed_dict(train):\n",
        "    \"\"\"Make a TensorFlow feed_dict: maps data onto Tensor placeholders.\"\"\"\n",
        "    if train or FLAGS.fake_data:\n",
        "      xs, ys = mnist.train.next_batch(100, fake_data=FLAGS.fake_data)\n",
        "      k = FLAGS.dropout\n",
        "    else:\n",
        "      xs, ys = mnist.test.images, mnist.test.labels\n",
        "      k = 1.0\n",
        "    return {x: xs, y_: ys, keep_prob: k}\n",
        "\n",
        "for i in range(FLAGS.max_steps):\n",
        "    if i % 10 == 0:  # Record summaries and test-set accuracy\n",
        "      summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))\n",
        "      test_writer.add_summary(summary, i)\n",
        "      print('Accuracy at step %s: %s' % (i, acc))\n",
        "    else:  # Record train set summaries, and train\n",
        "      if i % 100 == 99:  # Record execution stats\n",
        "        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
        "        run_metadata = tf.RunMetadata()\n",
        "        summary, _ = sess.run([merged, train_step],\n",
        "                              feed_dict=feed_dict(True),\n",
        "                              options=run_options,\n",
        "                              run_metadata=run_metadata)\n",
        "        train_writer.add_run_metadata(run_metadata, 'step%d' % i)\n",
        "        train_writer.add_summary(summary, i)\n",
        "        print('Adding run metadata for', i)\n",
        "      else:  # Record a summary\n",
        "        summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True))\n",
        "        train_writer.add_summary(summary, i)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8bdf455aba04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Record summaries and test-set accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'FLAGS' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "m8Rk92D7-vT_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}